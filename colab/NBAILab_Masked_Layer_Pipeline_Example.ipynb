{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NBAILab - Masked Layer Pipeline Example",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DR2xOHGrXdZl"
      },
      "source": [
        "# NBAILab - Masked Layer Pipeline Example\n",
        "<img src=\"https://raw.githubusercontent.com/NBAiLab/notram/master/images/nblogo_2.png\">\n",
        "\n",
        "In this notebook we load the [NB-BERTbase Model](https://github.com/NBAiLab/notram) released by the National Library of Norway. This is a model trained on a large corpus (110GB) of Norwegian texts. \n",
        "\n",
        "We load the model with the so called MLM-layer, a masked layer mainly used for training. The layer allows us to try to predict a \\[MASK\\]-token. This task is not very useful, however it gives us an idea of how well the language model understands the language.\n",
        "\n",
        "Here we use the [Transformers Library by Huggingface](https://huggingface.co/transformers/) pipeline giving an easy interface for loading models and running predictions.\n",
        "\n",
        "If you want to edit this file, you should create a copy of this notebook by going to \"File - Save a Copy in Drive\"\n",
        "\n",
        "## Install Transformers and Select Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYBm3dcAF-Av"
      },
      "source": [
        "!pip install -q transformers\n",
        "from transformers import pipeline\n",
        "\n",
        "model = 'NbAiLab/nb-bert-base' #@param [\"NbAiLab/nb-bert-base\", \"bert-base-multilingual-cased\",\"bert-base-cased\",\"ltgoslo/norbert\"]\n",
        "pipe = pipeline('fill-mask', model=model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrLhjlZyZ9ro"
      },
      "source": [
        "## Predict text\n",
        "The pipeline below will try to replace the \\[MASK\\]-token with the most likely word from the vocabulary file. In training this is used for improving the model. It can also be used to see if the model makes reasonable and grammatically correct sentences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZ363pAMHqtl"
      },
      "source": [
        "text = 'For å være sikker på at man har laget en god språkmodell må man [MASK] den først.' #@param {type:\"string\"}\n",
        "pipe(text)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}